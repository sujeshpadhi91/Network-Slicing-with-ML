{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["CnI3Yez2ty-9","IFDwyp06kUEi","hmSe9BzZkvrF","xhYMczXwqj-p","fKjOs1pArCEg","RiZfvelrtPG_","DYYYEn-gr2hl"],"authorship_tag":"ABX9TyMa1Z4b1L8KpWmzAH2pI4TN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["# **Data Pre-processing**"],"metadata":{"id":"CnI3Yez2ty-9"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n","from sklearn import metrics\n","from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc\n","from sklearn.preprocessing import label_binarize\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"sME48b2yy6Pp","executionInfo":{"status":"ok","timestamp":1709058505714,"user_tz":420,"elapsed":1597,"user":{"displayName":"SUJESH PADHI","userId":"09125795411447006355"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0YA0wIt_wJaq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Dataset/train_dataset.zip')\n","data.head()"],"metadata":{"id":"4Yv7WkOSxZW2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = data['slice Type']\n","y"],"metadata":{"id":"0Ck5zZgZ1IWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Class Distribution\n","plt.figure(figsize=(8, 5))\n","sns.countplot(x=y)\n","plt.title('Class Distribution')\n","plt.show()"],"metadata":{"id":"_YitI1FkWKCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# features = ['Packet Loss Rate', 'Packet delay', 'IoT',\t'LTE/5G',\t'GBR',\t'Non-GBR']\n","# features = ['Packet Loss Rate', 'IoT',\t'LTE/5G',\t'GBR',\t'Non-GBR']\n","# features = ['Packet Loss Rate', 'Packet delay']\n","# features = ['Packet Loss Rate']\n","\n","# features = ['AR/VR/Gaming',\t'Healthcare',\t'Industry 4.0', 'IoT Devices',\t'Public Safety',\t'Smart City & Home',\t'Smart Transportation',\t'Smartphone']\n","# features = ['AR/VR/Gaming',\t'Healthcare',\t'Industry 4.0', 'Public Safety']\n","# features = ['IoT Devices',\t'Smart City & Home',\t'Smart Transportation',\t'Smartphone']\n","# features = ['Smartphone']\n","# features = ['AR/VR/Gaming',\t'Healthcare',\t'Industry 4.0', 'IoT Devices',\t'Public Safety',\t'Smart City & Home',\t'Smart Transportation']\n","\n","features = ['Packet Loss Rate', 'Packet delay', 'IoT',\t'LTE/5G',\t'GBR',\t'Non-GBR', 'AR/VR/Gaming',\t'Healthcare',\t'Industry 4.0', 'IoT Devices',\t'Public Safety',\t'Smart City & Home',\t'Smart Transportation',\t'Smartphone']\n","# features = ['Packet Loss Rate', 'IoT',\t'LTE/5G',\t'GBR',\t'Non-GBR', 'AR/VR/Gaming',\t'Healthcare',\t'Industry 4.0', 'IoT Devices',\t'Public Safety',\t'Smart City & Home',\t'Smart Transportation',\t'Smartphone']\n","# features = ['Packet Loss Rate', 'Packet delay', 'AR/VR/Gaming',\t'Healthcare',\t'Industry 4.0', 'IoT Devices',\t'Public Safety',\t'Smart City & Home',\t'Smart Transportation',\t'Smartphone']\n","# features = ['Packet Loss Rate', 'Packet delay', 'AR/VR/Gaming',\t'Healthcare',\t'Industry 4.0', 'IoT Devices',\t'Public Safety',\t'Smart City & Home',\t'Smart Transportation']\n","# features = ['Packet Loss Rate', 'AR/VR/Gaming',\t'Healthcare',\t'Industry 4.0', 'IoT Devices',\t'Public Safety',\t'Smart City & Home',\t'Smart Transportation',\t'Smartphone']\n","\n","X = data[features]\n","X"],"metadata":{"id":"PSw_DvEo0w29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Feature Analysis\n","# pair_plot_data = pd.concat([X, y], axis=1)\n","# sns.pairplot(data=pair_plot_data, hue=\"slice Type\")\n","# plt.suptitle('Pair Plot for the Dataset', y=1.02)\n","# plt.show()"],"metadata":{"id":"vsFsL3nDXg-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n","X_train"],"metadata":{"id":"j5xMuUsyxo7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"hW6AGlgi2joZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test"],"metadata":{"id":"pI4797nQvtJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test"],"metadata":{"id":"S4nHhnDivuk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Class Distribution\n","plt.figure(figsize=(8, 5))\n","sns.countplot(x=y_train)\n","plt.title('Class Distribution in Training')\n","plt.show()"],"metadata":{"id":"LWtfvnXaXHaB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Class Distribution\n","plt.figure(figsize=(8, 5))\n","sns.countplot(x=y_test)\n","plt.title('Class Distribution in Testing')\n","plt.show()"],"metadata":{"id":"dHM7kKQnXWQg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **RANDOM FOREST CLASSIFIER**"],"metadata":{"id":"IFDwyp06kUEi"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier"],"metadata":{"id":"0koc_pDFlNV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_RFC = RandomForestClassifier()\n","model_RFC.fit(X_train, y_train)"],"metadata":{"id":"-foS6LZl2pr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_RFC = model_RFC.predict(X_test)"],"metadata":{"id":"mCNxOof_25HO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_RFC = accuracy_score(y_test, y_pred_RFC)\n","print(f\"Accuracy: {accuracy_RFC:.2f}\")"],"metadata":{"id":"IHPtRLyI25Di"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred_RFC))"],"metadata":{"id":"Cy-1NCm3242p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(confusion_matrix(y_test, y_pred_RFC))"],"metadata":{"id":"aAOYVPO-o5HH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["print(confusion_matrix(y_test, y_pred_LR))"],"metadata":{"id":"XIJvmNK6o33v"}},{"cell_type":"code","source":["# Feature Importance\n","feature_importance = model_RFC.feature_importances_\n","# features = np.arange(len(feature_importance))\n","\n","plt.figure(figsize=(2 * len(features), 6))\n","plt.bar(features, feature_importance)\n","plt.title('Feature Importance')\n","plt.xlabel('Feature Name')\n","plt.ylabel('Importance Score')\n","plt.show()"],"metadata":{"id":"Hbm5ardxdjb8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix\n","cm_RFC = confusion_matrix(y_test, y_pred_RFC)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_RFC, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n","plt.title('Confusion Matrix for Random Forest Classifier')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","\n","# # Add a legend to indicate class labels\n","# classes = np.unique(y)\n","# plt.xticks(np.arange(len(classes)) + 0.5, classes, rotation=45)\n","# plt.yticks(np.arange(len(classes)) + 0.5, classes, rotation=0)\n","\n","plt.show()"],"metadata":{"id":"_I8XrIs_rY2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the column names from the original DataFrame\n","X_test_column_names = X.columns.tolist()\n","\n","# Convert X_test to a pandas DataFrame\n","X_test_df_RFC = pd.DataFrame(X_test, columns=X_test_column_names)  # Replace X_test_column_names with your actual column names\n","X_test_with_predictions_RFC = X_test_df_RFC.copy()  # Create a copy to avoid modifying the original DataFrame\n","\n","# Resetting indices to avoid alignment issues\n","X_test_with_predictions_RFC.reset_index(drop=True, inplace=True)\n","y_test.reset_index(drop=True, inplace=True)\n","y_pred_RFC = pd.Series(y_pred_RFC, name='Predicted_Slice_Type')  # Convert y_pred to a pandas Series\n","\n","# Add y_test and y_pred columns to the DataFrame\n","X_test_with_predictions_RFC['Actual_Slice_Type'] = y_test\n","X_test_with_predictions_RFC['Predicted_Slice_Type'] = y_pred_RFC"],"metadata":{"id":"02vri3sY3v2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_column_names"],"metadata":{"id":"asKXgQpESKFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_with_predictions_RFC.head(20)"],"metadata":{"id":"WyiebSEOXjM2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Precision-Recall Curve for Multi-Class\n","\n","# Binarize the labels\n","y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","y_pred_RFC_bin = label_binarize(y_pred_RFC, classes=np.unique(y_pred_RFC))\n","\n","# Calculate precision-recall curve\n","precision = dict()\n","recall = dict()\n","average_precision = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_pred_RFC_bin[:, i])\n","    average_precision[i] = average_precision_score(y_test_bin[:, i], y_pred_RFC_bin[:, i])\n","\n","# Compute micro-average precision-recall curve and its average precision\n","precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test_bin.ravel(), y_pred_RFC_bin.ravel())\n","average_precision[\"micro\"] = average_precision_score(y_test_bin, y_pred_RFC_bin, average=\"micro\")\n","\n","# Plot micro-average Precision-Recall curve\n","plt.figure(figsize=(8, 6))\n","plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2, where='post')\n","plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2, color='b')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title(f'Micro-average Precision-Recall Curve (Average Precision = {average_precision[\"micro\"]:.2f})')\n","plt.show()"],"metadata":{"id":"W8dHMRTzKH51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ROC Curve for Multi-Class\n","\n","# Binarize the labels\n","# y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","# y_pred_RFC_bin = label_binarize(y_pred_RFC, classes=np.unique(y_pred_RFC))\n","\n","# Calculate ROC curve\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_RFC_bin[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and its AUC\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_RFC_bin.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","# Plot micro-average ROC curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr['micro'], tpr['micro'], color='darkorange', lw=2, label=f'Micro-average ROC Curve (AUC = {roc_auc[\"micro\"]:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"QL60i53VuTUQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Logistic Regression**"],"metadata":{"id":"hmSe9BzZkvrF"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression"],"metadata":{"id":"MzBZeT5qR__a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_LR = LogisticRegression()\n","model_LR.fit(X_train, y_train)"],"metadata":{"id":"5P2rxm2plS1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_LR = model_LR.predict(X_test)"],"metadata":{"id":"Ays2IHe3livI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_LR = accuracy_score(y_test, y_pred_LR)\n","print(f'Accuracy: {accuracy_LR}')"],"metadata":{"id":"1160pYa8l8ri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred_LR))"],"metadata":{"id":"BCPyWBoGl8vA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(confusion_matrix(y_test, y_pred_LR))"],"metadata":{"id":"RybZ2aL1owB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Importance\n","feature_importance = model_LR.coef_[0]\n","# features = np.arange(len(feature_importance))\n","\n","plt.figure(figsize=(2 * len(features), 6))\n","plt.bar(features, feature_importance)\n","plt.title('Feature Importance')\n","plt.xlabel('Feature Name')\n","plt.ylabel('Coefficient Value')\n","plt.show()"],"metadata":{"id":"0ZNOei15trZ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix\n","cm_LR = confusion_matrix(y_test, y_pred_LR)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_LR, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n","plt.title('Confusion Matrix for Logistic Regression')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","\n","# # Add a legend to indicate class labels\n","# classes = np.unique(y)\n","# plt.xticks(np.arange(len(classes)) + 0.5, classes, rotation=45)\n","# plt.yticks(np.arange(len(classes)) + 0.5, classes, rotation=0)\n","\n","plt.show()"],"metadata":{"id":"Rb5yIyxqtyaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the column names from the original DataFrame\n","X_test_column_names = X.columns.tolist()\n","\n","# Convert X_test to a pandas DataFrame\n","X_test_df_LR = pd.DataFrame(X_test, columns=X_test_column_names)  # Replace X_test_column_names with your actual column names\n","X_test_with_predictions_LR = X_test_df_LR.copy()  # Create a copy to avoid modifying the original DataFrame\n","\n","# Resetting indices to avoid alignment issues\n","X_test_with_predictions_LR.reset_index(drop=True, inplace=True)\n","y_test.reset_index(drop=True, inplace=True)\n","y_pred_LR = pd.Series(y_pred_LR, name='Predicted_Slice_Type')  # Convert y_pred to a pandas Series\n","\n","# Add y_test and y_pred columns to the DataFrame\n","X_test_with_predictions_LR['Actual_Slice_Type'] = y_test\n","X_test_with_predictions_LR['Predicted_Slice_Type'] = y_pred_LR"],"metadata":{"id":"mGCURq1smqqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_with_predictions_LR.head(20)"],"metadata":{"id":"uAV7uIx_nhue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Precision-Recall Curve for Multi-Class\n","\n","# Binarize the labels\n","y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","y_pred_LR_bin = label_binarize(y_pred_LR, classes=np.unique(y_pred_LR))\n","\n","# Calculate precision-recall curve\n","precision = dict()\n","recall = dict()\n","average_precision = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_pred_LR_bin[:, i])\n","    average_precision[i] = average_precision_score(y_test_bin[:, i], y_pred_LR_bin[:, i])\n","\n","# Compute micro-average precision-recall curve and its average precision\n","precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test_bin.ravel(), y_pred_LR_bin.ravel())\n","average_precision[\"micro\"] = average_precision_score(y_test_bin, y_pred_LR_bin, average=\"micro\")\n","\n","# Plot micro-average Precision-Recall curve\n","plt.figure(figsize=(8, 6))\n","plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2, where='post')\n","plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2, color='b')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title(f'Micro-average Precision-Recall Curve (Average Precision = {average_precision[\"micro\"]:.2f})')\n","plt.show()"],"metadata":{"id":"RlUSaEoqu4B9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ROC Curve for Multi-Class\n","\n","# Binarize the labels\n","# y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","# y_pred_LR_bin = label_binarize(y_pred_LR, classes=np.unique(y_pred_LR))\n","\n","# Calculate ROC curve\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_LR_bin[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and its AUC\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_LR_bin.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","# Plot micro-average ROC curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr['micro'], tpr['micro'], color='darkorange', lw=2, label=f'Micro-average ROC Curve (AUC = {roc_auc[\"micro\"]:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"1ArdeNMxu4CC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Naive Bayes**"],"metadata":{"id":"xhYMczXwqj-p"}},{"cell_type":"code","source":["from sklearn.naive_bayes import GaussianNB"],"metadata":{"id":"wBXIkKbXqjGT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_NB = GaussianNB()\n","model_NB.fit(X_train, y_train)"],"metadata":{"id":"hF8_L66Rqpys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_NB = model_NB.predict(X_test)"],"metadata":{"id":"PaD0aijEqqNT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_NB = accuracy_score(y_test, y_pred_NB)\n","print(f'Accuracy: {accuracy_NB}')"],"metadata":{"id":"kYqsrkr1qveb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred_NB))"],"metadata":{"id":"v3zYYbLZqzEc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(confusion_matrix(y_test, y_pred_NB))"],"metadata":{"id":"1QUym7gspR80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix\n","cm_NB = confusion_matrix(y_test, y_pred_NB)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_NB, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n","plt.title('Confusion Matrix for Naive Bayes')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","\n","# # Add a legend to indicate class labels\n","# classes = np.unique(y)\n","# plt.xticks(np.arange(len(classes)) + 0.5, classes, rotation=45)\n","# plt.yticks(np.arange(len(classes)) + 0.5, classes, rotation=0)\n","\n","plt.show()"],"metadata":{"id":"AbyFrAfO0MlC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the column names from the original DataFrame\n","X_test_column_names = X.columns.tolist()\n","\n","# Convert X_test to a pandas DataFrame\n","X_test_df_NB = pd.DataFrame(X_test, columns=X_test_column_names)  # Replace X_test_column_names with your actual column names\n","X_test_with_predictions_NB = X_test_df_NB.copy()  # Create a copy to avoid modifying the original DataFrame\n","\n","# Resetting indices to avoid alignment issues\n","X_test_with_predictions_NB.reset_index(drop=True, inplace=True)\n","y_test.reset_index(drop=True, inplace=True)\n","y_pred_NB = pd.Series(y_pred_NB, name='Predicted_Slice_Type')  # Convert y_pred to a pandas Series\n","\n","# Add y_test and y_pred columns to the DataFrame\n","X_test_with_predictions_NB['Actual_Slice_Type'] = y_test\n","X_test_with_predictions_NB['Predicted_Slice_Type'] = y_pred_NB"],"metadata":{"id":"0i0by5p-qz15"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_with_predictions_NB.head(20)"],"metadata":{"id":"2tQgFUQDq5GZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Precision-Recall Curve for Multi-Class\n","\n","# Binarize the labels\n","y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","y_pred_NB_bin = label_binarize(y_pred_NB, classes=np.unique(y_pred_NB))\n","\n","# Calculate precision-recall curve\n","precision = dict()\n","recall = dict()\n","average_precision = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_pred_NB_bin[:, i])\n","    average_precision[i] = average_precision_score(y_test_bin[:, i], y_pred_NB_bin[:, i])\n","\n","# Compute micro-average precision-recall curve and its average precision\n","precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test_bin.ravel(), y_pred_NB_bin.ravel())\n","average_precision[\"micro\"] = average_precision_score(y_test_bin, y_pred_NB_bin, average=\"micro\")\n","\n","# Plot micro-average Precision-Recall curve\n","plt.figure(figsize=(8, 6))\n","plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2, where='post')\n","plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2, color='b')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title(f'Micro-average Precision-Recall Curve (Average Precision = {average_precision[\"micro\"]:.2f})')\n","plt.show()"],"metadata":{"id":"b6YK8BB-vfFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ROC Curve for Multi-Class\n","\n","# Binarize the labels\n","# y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","# y_pred_NB_bin = label_binarize(y_pred_NB, classes=np.unique(y_pred_NB))\n","\n","# Calculate ROC curve\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_NB_bin[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and its AUC\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_NB_bin.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","# Plot micro-average ROC curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr['micro'], tpr['micro'], color='darkorange', lw=2, label=f'Micro-average ROC Curve (AUC = {roc_auc[\"micro\"]:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"gvqXwnj6vfFF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **KNN**"],"metadata":{"id":"fKjOs1pArCEg"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier"],"metadata":{"id":"-kV8hbSQrER0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Choose the number of neighbors (e.g., 3, 5, 7)\n","k = 5\n","model_KNN = KNeighborsClassifier(n_neighbors=k)\n","model_KNN.fit(X_train, y_train)"],"metadata":{"id":"HusSYOkirO7U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_KNN = model_KNN.predict(X_test)"],"metadata":{"id":"82FGsfhqrTTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_KNN = accuracy_score(y_test, y_pred_KNN)\n","print(f'Accuracy: {accuracy_KNN}')"],"metadata":{"id":"ZzdcRILDrXsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred_KNN))"],"metadata":{"id":"mlvR1OK2rbac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(confusion_matrix(y_test, y_pred_KNN))"],"metadata":{"id":"1_i1vh8HpkYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix\n","cm_KNN = confusion_matrix(y_test, y_pred_KNN)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_KNN, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n","plt.title('Confusion Matrix for K Nearest Neighbour')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","\n","# # Add a legend to indicate class labels\n","# classes = np.unique(y)\n","# plt.xticks(np.arange(len(classes)) + 0.5, classes, rotation=45)\n","# plt.yticks(np.arange(len(classes)) + 0.5, classes, rotation=0)\n","\n","plt.show()"],"metadata":{"id":"SrukzdoQ0gW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the column names from the original DataFrame\n","X_test_column_names = X.columns.tolist()\n","\n","# Convert X_test to a pandas DataFrame\n","X_test_df_KNN = pd.DataFrame(X_test, columns=X_test_column_names)  # Replace X_test_column_names with your actual column names\n","X_test_with_predictions_KNN = X_test_df_KNN.copy()  # Create a copy to avoid modifying the original DataFrame\n","\n","# Resetting indices to avoid alignment issues\n","X_test_with_predictions_KNN.reset_index(drop=True, inplace=True)\n","y_test.reset_index(drop=True, inplace=True)\n","y_pred_KNN = pd.Series(y_pred_KNN, name='Predicted_Slice_Type')  # Convert y_pred to a pandas Series\n","\n","# Add y_test and y_pred columns to the DataFrame\n","X_test_with_predictions_KNN['Actual_Slice_Type'] = y_test\n","X_test_with_predictions_KNN['Predicted_Slice_Type'] = y_pred_KNN"],"metadata":{"id":"0_RGXowurbqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_with_predictions_KNN.head(20)"],"metadata":{"id":"XxLxdjZ1rf9M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Precision-Recall Curve for Multi-Class\n","\n","# Binarize the labels\n","y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","y_pred_KNN_bin = label_binarize(y_pred_KNN, classes=np.unique(y_pred_KNN))\n","\n","# Calculate precision-recall curve\n","precision = dict()\n","recall = dict()\n","average_precision = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_pred_KNN_bin[:, i])\n","    average_precision[i] = average_precision_score(y_test_bin[:, i], y_pred_KNN_bin[:, i])\n","\n","# Compute micro-average precision-recall curve and its average precision\n","precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test_bin.ravel(), y_pred_KNN_bin.ravel())\n","average_precision[\"micro\"] = average_precision_score(y_test_bin, y_pred_KNN_bin, average=\"micro\")\n","\n","# Plot micro-average Precision-Recall curve\n","plt.figure(figsize=(8, 6))\n","plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2, where='post')\n","plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2, color='b')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title(f'Micro-average Precision-Recall Curve (Average Precision = {average_precision[\"micro\"]:.2f})')\n","plt.show()"],"metadata":{"id":"_mC6F3rfvgXV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ROC Curve for Multi-Class\n","\n","# Binarize the labels\n","# y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","# y_pred_KNN_bin = label_binarize(y_pred_KNN, classes=np.unique(y_pred_KNN))\n","\n","# Calculate ROC curve\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_KNN_bin[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and its AUC\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_KNN_bin.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","# Plot micro-average ROC curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr['micro'], tpr['micro'], color='darkorange', lw=2, label=f'Micro-average ROC Curve (AUC = {roc_auc[\"micro\"]:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"zmbnb7rjvgXV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Decision Tree**"],"metadata":{"id":"RiZfvelrtPG_"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier"],"metadata":{"id":"uoJJ8t50tRfq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_DT = DecisionTreeClassifier(random_state=42)\n","model_DT.fit(X_train, y_train)"],"metadata":{"id":"Mfx4frdUtSAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_DT = model_DT.predict(X_test)"],"metadata":{"id":"v3ZCkYhmqXgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_DT = accuracy_score(y_test, y_pred_DT)\n","print(f'Accuracy: {accuracy_DT}')"],"metadata":{"id":"n0iZiD8MtVeG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred_DT))"],"metadata":{"id":"O3_WAIU4tYW_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(confusion_matrix(y_test, y_pred_DT))"],"metadata":{"id":"ta4r5ft_qMNG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Importance\n","feature_importance = model_DT.feature_importances_\n","# features = np.arange(len(feature_importance))\n","\n","plt.figure(figsize=(2 * len(features), 6))\n","plt.bar(features, feature_importance)\n","plt.title('Feature Importance')\n","plt.xlabel('Feature Index')\n","plt.ylabel('Importance Score')\n","plt.show()"],"metadata":{"id":"e1G4SQSO1Cg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix\n","cm_DT = confusion_matrix(y_test, y_pred_DT)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_DT, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n","plt.title('Confusion Matrix for Decision Tree')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","\n","# # Add a legend to indicate class labels\n","# classes = np.unique(y)\n","# plt.xticks(np.arange(len(classes)) + 0.5, classes, rotation=45)\n","# plt.yticks(np.arange(len(classes)) + 0.5, classes, rotation=0)\n","\n","plt.show()"],"metadata":{"id":"XRmVwfVa1Cg7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the column names from the original DataFrame\n","X_test_column_names = X.columns.tolist()\n","\n","# Convert X_test to a pandas DataFrame\n","X_test_df_DT = pd.DataFrame(X_test, columns=X_test_column_names)  # Replace X_test_column_names with your actual column names\n","X_test_with_predictions_DT = X_test_df_DT.copy()  # Create a copy to avoid modifying the original DataFrame\n","\n","# Resetting indices to avoid alignment issues\n","X_test_with_predictions_DT.reset_index(drop=True, inplace=True)\n","y_test.reset_index(drop=True, inplace=True)\n","y_pred_DT = pd.Series(y_pred_DT, name='Predicted_Slice_Type')  # Convert y_pred to a pandas Series\n","\n","# Add y_test and y_pred columns to the DataFrame\n","X_test_with_predictions_DT['Actual_Slice_Type'] = y_test\n","X_test_with_predictions_DT['Predicted_Slice_Type'] = y_pred_DT"],"metadata":{"id":"pg2CFuMDtZJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_with_predictions_DT.head(20)"],"metadata":{"id":"Qm8ZsJV1tgfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Precision-Recall Curve for Multi-Class\n","\n","# Binarize the labels\n","y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","y_pred_DT_bin = label_binarize(y_pred_DT, classes=np.unique(y_pred_DT))\n","\n","# Calculate precision-recall curve\n","precision = dict()\n","recall = dict()\n","average_precision = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_pred_DT_bin[:, i])\n","    average_precision[i] = average_precision_score(y_test_bin[:, i], y_pred_DT_bin[:, i])\n","\n","# Compute micro-average precision-recall curve and its average precision\n","precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test_bin.ravel(), y_pred_DT_bin.ravel())\n","average_precision[\"micro\"] = average_precision_score(y_test_bin, y_pred_DT_bin, average=\"micro\")\n","\n","# Plot micro-average Precision-Recall curve\n","plt.figure(figsize=(8, 6))\n","plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2, where='post')\n","plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2, color='b')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title(f'Micro-average Precision-Recall Curve (Average Precision = {average_precision[\"micro\"]:.2f})')\n","plt.show()"],"metadata":{"id":"Raz_eGZKvi1e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ROC Curve for Multi-Class\n","\n","# Binarize the labels\n","# y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","# y_pred_DT_bin = label_binarize(y_pred_DT, classes=np.unique(y_pred_DT))\n","\n","# Calculate ROC curve\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_DT_bin[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and its AUC\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_DT_bin.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","# Plot micro-average ROC curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr['micro'], tpr['micro'], color='darkorange', lw=2, label=f'Micro-average ROC Curve (AUC = {roc_auc[\"micro\"]:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"rK3n7Yemvi1e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Support Vector Machine**"],"metadata":{"id":"DYYYEn-gr2hl"}},{"cell_type":"code","source":["from sklearn.svm import SVC"],"metadata":{"id":"wPWFvPMbr6jg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Types of SVM (linear, polynomial, radial basis function, etc.)\n","# Here, we use a linear kernel for simplicity\n","model_SVM = SVC(kernel='linear')\n","model_SVM.fit(X_train, y_train)"],"metadata":{"id":"1cZpAFJGr697"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_SVM = model_SVM.predict(X_test)"],"metadata":{"id":"x8h1yODzsFOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_SVM = accuracy_score(y_test, y_pred_SVM)\n","print(f'Accuracy: {accuracy_SVM}')"],"metadata":{"id":"GT5pn5U1sHm1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred_SVM))"],"metadata":{"id":"vkAJwFCksMXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(confusion_matrix(y_test, y_pred_SVM))"],"metadata":{"id":"0Ar3Kvnjp2TS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix\n","cm_SVM = confusion_matrix(y_test, y_pred_SVM)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_SVM, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n","plt.title('Confusion Matrix for Support Vector Machine')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","\n","# # Add a legend to indicate class labels\n","# classes = np.unique(y)\n","# plt.xticks(np.arange(len(classes)) + 0.5, classes, rotation=45)\n","# plt.yticks(np.arange(len(classes)) + 0.5, classes, rotation=0)\n","\n","plt.show()"],"metadata":{"id":"5Wy0PTA300Sa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the column names from the original DataFrame\n","X_test_column_names = X.columns.tolist()\n","\n","# Convert X_test to a pandas DataFrame\n","X_test_df_SVM = pd.DataFrame(X_test, columns=X_test_column_names)  # Replace X_test_column_names with your actual column names\n","X_test_with_predictions_SVM = X_test_df_SVM.copy()  # Create a copy to avoid modifying the original DataFrame\n","\n","# Resetting indices to avoid alignment issues\n","X_test_with_predictions_SVM.reset_index(drop=True, inplace=True)\n","y_test.reset_index(drop=True, inplace=True)\n","y_pred = pd.Series(y_pred_SVM, name='Predicted_Slice_Type')  # Convert y_pred to a pandas Series\n","\n","# Add y_test and y_pred columns to the DataFrame\n","X_test_with_predictions_SVM['Actual_Slice_Type'] = y_test\n","X_test_with_predictions_SVM['Predicted_Slice_Type'] = y_pred_SVM"],"metadata":{"id":"sv0-NBlKsNPX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_with_predictions_SVM.head(20)"],"metadata":{"id":"uHNDO3dcsSOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Precision-Recall Curve for Multi-Class\n","\n","# Binarize the labels\n","y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","y_pred_SVM_bin = label_binarize(y_pred_SVM, classes=np.unique(y_pred_SVM))\n","\n","# Calculate precision-recall curve\n","precision = dict()\n","recall = dict()\n","average_precision = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_pred_SVM_bin[:, i])\n","    average_precision[i] = average_precision_score(y_test_bin[:, i], y_pred_SVM_bin[:, i])\n","\n","# Compute micro-average precision-recall curve and its average precision\n","precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test_bin.ravel(), y_pred_SVM_bin.ravel())\n","average_precision[\"micro\"] = average_precision_score(y_test_bin, y_pred_SVM_bin, average=\"micro\")\n","\n","# Plot micro-average Precision-Recall curve\n","plt.figure(figsize=(8, 6))\n","plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2, where='post')\n","plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2, color='b')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title(f'Micro-average Precision-Recall Curve (Average Precision = {average_precision[\"micro\"]:.2f})')\n","plt.show()"],"metadata":{"id":"eyUiIrpbvhpw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ROC Curve for Multi-Class\n","\n","# Binarize the labels\n","# y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","# y_pred_SVM_bin = label_binarize(y_pred_SVM, classes=np.unique(y_pred_SVM))\n","\n","# Calculate ROC curve\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","# Loop over each class\n","for i in range(len(np.unique(y_test))):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_SVM_bin[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and its AUC\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_SVM_bin.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","# Plot micro-average ROC curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr['micro'], tpr['micro'], color='darkorange', lw=2, label=f'Micro-average ROC Curve (AUC = {roc_auc[\"micro\"]:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"__qVaV3Lvhpw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **SYNC NOTEBOOKS**"],"metadata":{"id":"opqsgcSXQbIM"}},{"cell_type":"code","source":["%cp '/content/drive/MyDrive/Colab Notebooks/Exp1 - Slice_Classification_SupML.ipynb' '/content/drive/MyDrive/Network_Slicing_with_ML_repo/Network-Slicing-with-ML/Notebooks/'"],"metadata":{"id":"A2_2tantQeX8"},"execution_count":null,"outputs":[]}]}